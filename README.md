# DSSM: DUAL STATE SPACE MODEL FOR HUMAN MOTIONS GENERATION (icassp 2025 submitting)

![teaser_image](https://github.com/yimingliu123/DSSM/blob/main/training.png)

We will continue to supplement and complete our code as soon as possible.


## :postbox: News
ðŸ“¢ **2024-09-11** --- Initialized the webpage and git project.  

ðŸ“¢ **2024-09-11** --- The paper was submitted to icassp2025.


  
### 1. Conda Environment
```
conda env create -f environment.yml
conda activate DSSM
pip install git+https://github.com/openai/CLIP.git
```
We test our code on Python 3.7.13 and PyTorch 1.7.1

#### Alternative: Pip Installation
<details>
We provide an alternative pip installation in case you encounter difficulties setting up the conda environment.

```
pip install -r requirements.txt
```
We test this installation on Python 3.10

</details>

### 2. Models and Dependencies

#### Download Pre-trained Models
```
bash prepare/download_models.sh
```


### 3. Get Data

You have two options here:
* **Skip getting data**, if you just want to generate motions using *own* descriptions.
* **Get full data**, if you want to *re-train* and *evaluate* the model.

**(a). Full data (text + motion)**

**HumanML3D** - Follow the instruction in [HumanML3D](https://github.com/EricGuo5513/HumanML3D.git), then copy the result dataset to our repository:
```
cp -r ../HumanML3D/HumanML3D ./dataset/HumanML3D
```
**KIT**-Download from [HumanML3D](https://github.com/EricGuo5513/HumanML3D.git), then place result in `./dataset/KIT-ML`



## License

Note that our code depends on momask.
```
@article{guo2023momask,
      title={MoMask: Generative Masked Modeling of 3D Human Motions}, 
      author={Chuan Guo and Yuxuan Mu and Muhammad Gohar Javed and Sen Wang and Li Cheng},
      year={2023},
      eprint={2312.00063},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

